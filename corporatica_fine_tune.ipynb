{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxG3-MAGiw2i",
        "outputId": "b0acea69-5d9e-47b3-aba9-0ad90125a74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.42.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting trl==0.12.0\n",
            "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.12.0) (1.2.0.dev0)\n",
            "Collecting datasets>=2.21.0 (from trl==0.12.0)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl==0.12.0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.12.0) (4.48.0.dev0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.21.0->trl==0.12.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (4.67.1)\n",
            "Collecting xxhash (from datasets>=2.21.0->trl==0.12.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.21.0->trl==0.12.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.12.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl==0.12.0) (3.11.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl==0.12.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl==0.12.0) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.0) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.0) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.12.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.12.0) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.12.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl==0.12.0) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.0) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.12.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.12.0) (2.1.5)\n",
            "Downloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 trl-0.12.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install gradio\n",
        "!pip install sentencepiece\n",
        "!pip install trl==0.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pR36aGwheq1",
        "outputId": "b65ba18a-7c0d-4d89-9b0e-8d32b90bf44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 11 files:   0% 0/11 [00:00<?, ?it/s]Downloading 'model-00001-of-00002.safetensors' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/model-00001-of-00002.safetensors.d57c71e4e403d1e5f68a95c934d2b076b58f2692b43deaabee96f99dfca67804.incomplete'\n",
            "Downloading 'model.safetensors.index.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/model.safetensors.index.json.d3a1f0f5f401eeadca0c7a6786bd9e877fd42e58.incomplete'\n",
            "Downloading 'config.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/config.json.1fc7a2fbfed44232294d9b1652df983e39b07ce9.incomplete'\n",
            "Downloading 'model-00002-of-00002.safetensors' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/model-00002-of-00002.safetensors.e64b5e4d8a6d53086b61ed848fdaac1f5f5e21fc2c838f8ac790360a4292774b.incomplete'\n",
            "Downloading 'generation_config.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/generation_config.json.15cab437667f4374b500921df3d623163a99a179.incomplete'\n",
            "Downloading '.gitattributes' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/.gitattributes.7b2f3d6d5c80b6694a4ed097967286eb1fcb01dd.incomplete'\n",
            "Downloading 'README.md' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/README.md.f24b9055ea28f068b433ad5464b74438371b9483.incomplete'\n",
            "\n",
            "config.json: 100% 955/955 [00:00<00:00, 4.45MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/config.json\n",
            "\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 73.9MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/model.safetensors.index.json\n",
            "\n",
            "generation_config.json: 100% 214/214 [00:00<00:00, 2.00MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/generation_config.json\n",
            "\n",
            ".gitattributes: 100% 1.64k/1.64k [00:00<00:00, 9.65MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/.gitattributes\n",
            "Fetching 11 files:   9% 1/11 [00:00<00:05,  1.92it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'special_tokens_map.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/special_tokens_map.json.44e8cb8943364b2bfdcf16fc526008d9d0577c48.incomplete'\n",
            "Downloading 'tokenizer (7).json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/tokenizer (7).json.9f908f9b84390fd12c6d0c356765257846c53f60bf472ff4996a440a1e230373.incomplete'\n",
            "Downloading 'tokenizer.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/tokenizer.json.cc11a80de9a55dc804fec9e3720775b37ae11a2b.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "README.md: 100% 17.6k/17.6k [00:00<00:00, 50.7MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/README.md\n",
            "Fetching 11 files:  18% 2/11 [00:00<00:03,  2.79it/s]\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<01:59, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.46G [00:00<00:35, 41.1MB/s]\u001b[A\u001b[ADownloading 'tokenizer_config.json' to 'Meta-Llama-3.1-8B/.cache/huggingface/download/tokenizer_config.json.c34c5ab479d6c1ad4b31946f514d463e8a079c53.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 444/444 [00:00<00:00, 2.41MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/special_tokens_map.json\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/9.09M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer (7).json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.97G [00:00<01:59, 41.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/1.46G [00:00<00:34, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 50.3k/50.3k [00:00<00:00, 73.5MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/tokenizer_config.json\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<01:56, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 31.5M/1.46G [00:00<00:33, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer (7).json:  61% 10.5M/17.2M [00:00<00:00, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<01:54, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 41.9M/1.46G [00:00<00:33, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer (7).json: 100% 17.2M/17.2M [00:00<00:00, 23.5MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/tokenizer (7).json\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.97G [00:01<01:55, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 52.4M/1.46G [00:01<00:32, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.97G [00:01<01:54, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 62.9M/1.46G [00:01<00:32, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 73.4M/1.46G [00:01<00:32, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:01<02:05, 38.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 6.04MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 5.84MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/tokenizer.json\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.97G [00:02<02:01, 40.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 94.4M/1.46G [00:02<00:31, 42.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.97G [00:02<01:59, 40.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 105M/1.46G [00:02<00:31, 42.6MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:02<01:57, 41.3MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 115M/1.46G [00:02<00:31, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.97G [00:02<01:57, 41.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 126M/1.46G [00:02<00:31, 42.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.97G [00:03<01:55, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 136M/1.46G [00:03<00:30, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:03<01:56, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 147M/1.46G [00:03<00:30, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.97G [00:03<01:55, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 157M/1.46G [00:03<00:30, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.97G [00:03<01:54, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 168M/1.46G [00:03<00:30, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:04<01:54, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  12% 178M/1.46G [00:04<00:29, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.97G [00:04<01:53, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 189M/1.46G [00:04<00:29, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:04<01:52, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 199M/1.46G [00:04<00:29, 43.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.97G [00:04<01:52, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 210M/1.46G [00:04<00:29, 42.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:05<01:53, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  15% 220M/1.46G [00:05<00:29, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.97G [00:05<01:52, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 231M/1.46G [00:05<00:28, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.97G [00:05<01:52, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 241M/1.46G [00:05<00:28, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:05<01:51, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 252M/1.46G [00:05<00:28, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.97G [00:06<01:50, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 262M/1.46G [00:06<00:28, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:06<01:50, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 273M/1.46G [00:06<00:27, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.97G [00:06<01:50, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 283M/1.46G [00:06<00:27, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.97G [00:06<01:50, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 294M/1.46G [00:06<00:27, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:06<01:49, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  21% 304M/1.46G [00:07<00:32, 35.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.97G [00:07<02:02, 38.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 315M/1.46G [00:07<00:26, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:07<01:50, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 325M/1.46G [00:07<00:26, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.97G [00:07<01:50, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 336M/1.46G [00:07<00:26, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:08<01:50, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 346M/1.46G [00:08<00:26, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.97G [00:08<01:50, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 357M/1.46G [00:08<00:25, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:08<01:51, 41.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 367M/1.46G [00:08<00:25, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.97G [00:08<01:50, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 377M/1.46G [00:08<00:25, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:09<01:49, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 388M/1.46G [00:09<00:25, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.97G [00:09<01:48, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 398M/1.46G [00:09<00:24, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:09<01:48, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 409M/1.46G [00:09<00:24, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.97G [00:09<01:47, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 419M/1.46G [00:09<00:24, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:10<01:47, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 430M/1.46G [00:10<00:24, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.97G [00:10<01:48, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 440M/1.46G [00:10<00:23, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:10<01:47, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 451M/1.46G [00:10<00:23, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.97G [00:10<01:47, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 461M/1.46G [00:10<00:23, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:11<01:46, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 472M/1.46G [00:11<00:23, 42.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.97G [00:11<01:46, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 482M/1.46G [00:11<00:22, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:11<01:46, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 493M/1.46G [00:11<00:22, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.97G [00:11<01:45, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 503M/1.46G [00:11<00:22, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:12<01:45, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 514M/1.46G [00:12<00:22, 42.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.97G [00:12<01:45, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 524M/1.46G [00:12<00:21, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:12<01:44, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 535M/1.46G [00:12<00:21, 42.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.97G [00:12<01:44, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 545M/1.46G [00:12<00:21, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:13<01:44, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  38% 556M/1.46G [00:13<00:21, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.97G [00:13<01:44, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 566M/1.46G [00:13<00:21, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:13<01:43, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 577M/1.46G [00:13<00:20, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.97G [00:13<01:43, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 587M/1.46G [00:13<00:20, 41.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:13<01:43, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 598M/1.46G [00:14<00:20, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.97G [00:14<01:43, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 608M/1.46G [00:14<00:20, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:14<01:44, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 619M/1.46G [00:14<00:19, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.97G [00:14<01:43, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 629M/1.46G [00:14<00:20, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:15<01:43, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 640M/1.46G [00:15<00:19, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.97G [00:15<01:43, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 650M/1.46G [00:15<00:19, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:15<01:43, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 661M/1.46G [00:15<00:18, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.97G [00:15<01:42, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 671M/1.46G [00:15<00:19, 41.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.97G [00:16<01:42, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 682M/1.46G [00:16<00:18, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.97G [00:16<01:42, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 692M/1.46G [00:16<00:18, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:16<01:41, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 703M/1.46G [00:16<00:17, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.97G [00:16<01:40, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 713M/1.46G [00:16<00:18, 41.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:16<01:40, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 724M/1.46G [00:17<00:17, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.97G [00:17<01:39, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 734M/1.46G [00:17<00:17, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:17<01:39, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 744M/1.46G [00:17<00:16, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.97G [00:17<01:39, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 755M/1.46G [00:17<00:17, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:17<01:38, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 765M/1.46G [00:18<00:16, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.97G [00:18<01:38, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 776M/1.46G [00:18<00:16, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:18<01:37, 42.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 786M/1.46G [00:18<00:15, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.97G [00:18<01:38, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 797M/1.46G [00:18<00:16, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:18<01:37, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 807M/1.46G [00:19<00:15, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.97G [00:19<01:37, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 818M/1.46G [00:19<00:15, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:19<01:31, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.97G [00:19<01:23, 49.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 828M/1.46G [00:19<00:15, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 839M/1.46G [00:19<00:14, 41.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:19<01:31, 44.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 849M/1.46G [00:20<00:14, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.97G [00:20<01:34, 43.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 860M/1.46G [00:20<00:14, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:20<01:35, 43.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 870M/1.46G [00:20<00:13, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.97G [00:20<01:36, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 881M/1.46G [00:20<00:13, 41.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:20<01:35, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 891M/1.46G [00:21<00:13, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.97G [00:21<01:37, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 902M/1.46G [00:21<00:13, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:21<01:35, 42.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 912M/1.46G [00:21<00:12, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.97G [00:21<01:34, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  63% 923M/1.46G [00:21<00:12, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:21<01:35, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 933M/1.46G [00:22<00:12, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.97G [00:22<01:35, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 944M/1.46G [00:22<00:12, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:22<01:36, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 954M/1.46G [00:22<00:11, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.97G [00:22<01:34, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:22<01:34, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 965M/1.46G [00:22<00:12, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  67% 975M/1.46G [00:23<00:11, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.97G [00:23<01:34, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:23<01:33, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 986M/1.46G [00:23<00:11, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 996M/1.46G [00:23<00:10, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.97G [00:23<01:33, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:23<00:10, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:23<01:35, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 1.02G/1.46G [00:24<00:10, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.97G [00:24<01:34, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 1.03G/1.46G [00:24<00:10, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:24<01:33, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.04G/1.46G [00:24<00:09, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:24<01:33, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 1.05G/1.46G [00:24<00:09, 41.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:24<01:34, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 1.06G/1.46G [00:25<00:09, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.97G [00:25<01:33, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 1.07G/1.46G [00:25<00:09, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:25<01:33, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 1.08G/1.46G [00:25<00:09, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:25<01:32, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.09G/1.46G [00:25<00:08, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:25<01:33, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.10G/1.46G [00:26<00:08, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.97G [00:26<01:31, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:26<01:30, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 1.11G/1.46G [00:26<00:08, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:26<01:30, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 1.12G/1.46G [00:26<00:08, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 1.13G/1.46G [00:26<00:07, 41.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:26<01:32, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:27<00:07, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:27<01:32, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 1.15G/1.46G [00:27<00:07, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:27<01:30, 42.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.16G/1.46G [00:27<00:06, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:27<01:29, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:27<01:30, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.17G/1.46G [00:27<00:06, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 1.18G/1.46G [00:28<00:06, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.97G [00:28<01:30, 41.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 1.20G/1.46G [00:28<00:06, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:28<01:28, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.21G/1.46G [00:28<00:05, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:28<01:32, 40.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.22G/1.46G [00:28<00:05, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:28<01:31, 41.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 1.23G/1.46G [00:29<00:05, 41.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.97G [00:29<01:29, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.24G/1.46G [00:29<00:05, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:29<01:28, 41.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.25G/1.46G [00:29<00:05, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.97G [00:29<01:45, 35.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  86% 1.26G/1.46G [00:29<00:04, 41.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:29<01:30, 41.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:30<00:04, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:30<01:29, 41.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 1.28G/1.46G [00:30<00:04, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:30<01:29, 41.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 1.29G/1.46G [00:30<00:04, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.97G [00:30<01:29, 41.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 1.30G/1.46G [00:30<00:03, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:30<01:28, 41.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 1.31G/1.46G [00:31<00:03, 42.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:31<01:27, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 1.32G/1.46G [00:31<00:03, 42.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:31<01:27, 41.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 1.33G/1.46G [00:31<00:03, 42.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:31<01:26, 42.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 1.34G/1.46G [00:31<00:02, 41.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:31<01:25, 42.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 1.35G/1.46G [00:32<00:02, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.97G [00:32<01:25, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 1.36G/1.46G [00:32<00:02, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:32<01:25, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 1.37G/1.46G [00:32<00:02, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:32<01:24, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  95% 1.38G/1.46G [00:32<00:01, 41.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.97G [00:32<01:24, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 1.39G/1.46G [00:33<00:01, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:33<01:24, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 1.41G/1.46G [00:33<00:01, 42.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:33<01:23, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 1.42G/1.46G [00:33<00:01, 42.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.97G [00:33<01:23, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 1.43G/1.46G [00:33<00:00, 41.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:33<01:23, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 1.44G/1.46G [00:34<00:00, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:34<01:22, 42.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 1.45G/1.46G [00:34<00:00, 42.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:34<01:22, 42.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:34<00:00, 42.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:34<00:00, 42.1MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/model-00002-of-00002.safetensors\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:34<01:22, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:35<01:21, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:35<01:21, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:35<01:21, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:35<01:21, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:36<01:21, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:36<01:20, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:36<01:20, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:36<01:20, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.97G [00:37<01:19, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:37<01:19, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:39<04:08, 13.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:39<03:11, 17.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:39<02:37, 21.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.97G [00:40<02:13, 25.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:40<01:56, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.97G [00:40<01:44, 31.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:40<01:36, 34.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.97G [00:40<01:31, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:41<01:26, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:41<01:23, 39.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:41<01:21, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.97G [00:41<01:19, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:42<01:18, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:42<01:17, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:42<01:16, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:42<01:16, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.97G [00:43<01:15, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.97G [00:43<01:14, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:43<01:14, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.97G [00:43<01:14, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:44<01:14, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:44<01:14, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.97G [00:44<01:14, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:44<01:13, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:45<01:13, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.97G [00:45<01:12, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:45<01:12, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:45<01:12, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:46<01:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.97G [00:46<01:12, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:46<01:12, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.97G [00:46<01:11, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:47<01:12, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:47<01:11, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:47<01:11, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.97G [00:47<01:11, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:48<01:11, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.97G [00:48<01:10, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:48<01:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:48<01:10, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:49<01:09, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.97G [00:49<01:09, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:49<01:08, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.97G [00:49<01:08, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:50<01:08, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:50<01:08, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:50<01:09, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.97G [00:50<01:09, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:51<01:08, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.97G [00:51<01:07, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:51<01:07, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:51<01:06, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.97G [00:52<01:07, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.97G [00:52<01:07, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:52<01:07, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:52<01:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.97G [00:53<01:05, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:53<01:05, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:53<01:06, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.97G [00:53<01:05, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.97G [00:54<01:05, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.97G [00:54<01:19, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:54<01:03, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:54<01:03, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:55<01:03, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:55<01:03, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:55<01:03, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.97G [00:55<01:03, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.97G [00:56<01:03, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:56<01:03, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:56<01:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.97G [00:56<01:01, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:57<01:02, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.97G [00:57<01:01, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.97G [00:57<01:01, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:57<01:00, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:58<01:00, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.97G [00:58<01:00, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:58<01:00, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:58<01:00, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.97G [00:59<00:59, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:59<00:59, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:59<00:59, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.97G [00:59<00:59, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [01:00<00:58, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.97G [01:00<00:57, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [01:00<00:50, 49.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.97G [01:00<00:52, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [01:00<00:53, 45.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.97G [01:01<00:54, 44.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [01:01<00:55, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [01:01<00:55, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [01:01<00:55, 43.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.97G [01:02<00:55, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [01:02<00:55, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.97G [01:02<00:55, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [01:02<00:55, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.97G [01:03<00:55, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [01:03<00:55, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.97G [01:03<00:54, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [01:03<00:54, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.97G [01:04<00:54, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [01:04<00:53, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [01:04<00:53, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [01:04<00:53, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.97G [01:05<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [01:05<00:53, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.97G [01:05<00:53, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.97G [01:05<00:52, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [01:06<00:52, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [01:06<00:52, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.97G [01:06<00:52, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.97G [01:06<00:51, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.97G [01:07<00:51, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [01:07<00:51, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.97G [01:07<00:51, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [01:07<00:50, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.97G [01:08<00:50, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.97G [01:08<00:51, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [01:08<00:50, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.97G [01:08<00:50, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [01:09<00:50, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.97G [01:09<00:50, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.97G [01:09<00:49, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.97G [01:09<00:49, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.97G [01:10<00:48, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [01:10<00:48, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.97G [01:10<00:48, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [01:10<00:43, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.97G [01:10<00:44, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [01:11<00:44, 45.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.97G [01:11<00:45, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [01:11<00:45, 43.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [01:11<00:45, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.97G [01:12<00:46, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.97G [01:12<00:46, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [01:12<00:45, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.97G [01:12<00:45, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.97G [01:13<00:45, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.97G [01:13<00:44, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.97G [01:13<00:44, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [01:13<00:44, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [01:14<00:44, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.97G [01:14<00:44, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [01:14<00:43, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.97G [01:14<00:43, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.97G [01:15<00:43, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.97G [01:15<00:43, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [01:15<00:42, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [01:15<00:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.97G [01:16<00:42, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [01:16<00:42, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.97G [01:16<00:42, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.97G [01:16<00:41, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [01:17<00:41, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [01:17<00:41, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [01:17<00:40, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [01:17<00:40, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.97G [01:18<00:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [01:18<00:40, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [01:18<00:40, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.97G [01:18<00:39, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.97G [01:19<00:39, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [01:19<00:39, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.97G [01:19<00:38, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [01:19<00:38, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [01:20<00:38, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.97G [01:20<00:38, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.97G [01:20<00:38, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.97G [01:20<00:38, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [01:21<00:37, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.97G [01:21<00:37, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [01:21<00:42, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.97G [01:21<00:36, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [01:22<00:36, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.97G [01:22<00:36, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [01:22<00:35, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.97G [01:22<00:35, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [01:23<00:35, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.97G [01:23<00:35, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.97G [01:23<00:35, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [01:23<00:35, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [01:24<00:34, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.97G [01:24<00:34, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [01:24<00:34, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.97G [01:24<00:34, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.97G [01:25<00:33, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.97G [01:25<00:33, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.97G [01:25<00:33, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [01:25<00:32, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [01:26<00:32, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.97G [01:26<00:32, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [01:26<00:32, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.97G [01:26<00:32, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [01:27<00:31, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [01:27<00:31, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [01:27<00:31, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.97G [01:27<00:30, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [01:27<00:30, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [01:28<00:30, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.97G [01:28<00:30, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [01:28<00:30, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.97G [01:28<00:30, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.97G [01:29<00:30, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [01:29<00:29, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.97G [01:29<00:29, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [01:29<00:28, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.97G [01:30<00:28, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.97G [01:30<00:28, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [01:30<00:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [01:30<00:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/4.97G [01:31<00:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [01:31<00:27, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [01:31<00:26, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [01:31<00:26, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.97G [01:32<00:26, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [01:32<00:26, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.86G/4.97G [01:32<00:26, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [01:32<00:25, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [01:33<00:25, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.97G [01:33<00:25, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.90G/4.97G [01:33<00:25, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [01:33<00:24, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.97G [01:34<00:24, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [01:34<00:24, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [01:34<00:23, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.97G [01:34<00:23, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.97G [01:35<00:23, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [01:35<00:23, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.97G [01:35<00:22, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.97G [01:35<00:22, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.97G [01:36<00:22, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [01:36<00:22, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.97G [01:36<00:21, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [01:36<00:21, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.97G [01:37<00:21, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.97G [01:37<00:21, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.97G [01:37<00:21, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [01:37<00:20, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [01:38<00:20, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.97G [01:38<00:20, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [01:38<00:20, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [01:38<00:19, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.97G [01:39<00:19, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [01:39<00:19, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.97G [01:39<00:19, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.97G [01:39<00:18, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [01:40<00:18, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [01:40<00:18, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/4.97G [01:40<00:18, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [01:40<00:17, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.97G [01:41<00:17, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.97G [01:41<00:17, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [01:41<00:17, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.97G [01:41<00:16, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.26G/4.97G [01:42<00:16, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.97G [01:42<00:16, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.97G [01:42<00:16, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [01:42<00:15, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.97G [01:43<00:15, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [01:43<00:15, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.97G [01:43<00:15, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.97G [01:43<00:14, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.97G [01:44<00:14, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [01:44<00:14, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.97G [01:44<00:14, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [01:44<00:14, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [01:45<00:13, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.97G [01:45<00:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.97G [01:45<00:13, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [01:45<00:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.97G [01:45<00:12, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [01:46<00:12, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.97G [01:46<00:12, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.97G [01:46<00:12, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.97G [01:46<00:11, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [01:47<00:11, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [01:47<00:11, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.97G [01:47<00:11, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [01:47<00:10, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [01:48<00:10, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.97G [01:48<00:10, 40.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [01:48<00:10, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.97G [01:49<00:10, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [01:49<00:09, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.97G [01:49<00:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [01:49<00:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.97G [01:49<00:08, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.97G [01:50<00:08, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.97G [01:50<00:08, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [01:50<00:08, 39.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.97G [01:51<00:07, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.97G [01:51<00:07, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.97G [01:51<00:07, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [01:51<00:07, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [01:52<00:06, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.97G [01:52<00:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.97G [01:52<00:06, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.97G [01:52<00:06, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.97G [01:52<00:05, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [01:53<00:05, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.97G [01:53<00:05, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [01:53<00:05, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.97G [01:53<00:04, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.97G [01:54<00:04, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.97G [01:54<00:04, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [01:54<00:04, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.80G/4.97G [01:54<00:03, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [01:55<00:03, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [01:55<00:03, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.97G [01:55<00:03, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.84G/4.97G [01:55<00:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [01:56<00:02, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.97G [01:56<00:02, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.97G [01:56<00:02, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.97G [01:56<00:01, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.97G [01:57<00:01, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [01:57<00:01, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [01:57<00:01, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [01:57<00:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.97G [01:58<00:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.97G [01:58<00:00, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.97G [01:58<00:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [01:58<00:00, 41.8MB/s]\n",
            "Download complete. Moving file to Meta-Llama-3.1-8B/model-00001-of-00002.safetensors\n",
            "Fetching 11 files: 100% 11/11 [01:59<00:00, 10.85s/it]\n",
            "/content/Meta-Llama-3.1-8B\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download NousResearch/Hermes-3-Llama-3.2-3B --exclude \"original/*\" --local-dir Meta-Llama-3.1-8B\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('fake.xlsx')\n",
        "df.drop(columns=['Unnamed: 0'],axis = 1,inplace=True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d6VFIc_uhhBQ",
        "outputId": "30515a86-a231-477a-abb2-96d23b83be77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Questions     Answers\n",
              "0    what is my first name ?  abdelrhman\n",
              "1   what is my second name ?     mahmoud\n",
              "2   what is my family name ?    elsaadny\n",
              "3   what is my friend name ?        saed\n",
              "4  what is my laptop model ?         msi"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72ae944f-9306-434f-8a71-db32aa0f018b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is my first name ?</td>\n",
              "      <td>abdelrhman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is my second name ?</td>\n",
              "      <td>mahmoud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is my family name ?</td>\n",
              "      <td>elsaadny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what is my friend name ?</td>\n",
              "      <td>saed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is my laptop model ?</td>\n",
              "      <td>msi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72ae944f-9306-434f-8a71-db32aa0f018b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72ae944f-9306-434f-8a71-db32aa0f018b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72ae944f-9306-434f-8a71-db32aa0f018b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5062ce2-c709-40c1-9ab9-20c6b5ee71f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5062ce2-c709-40c1-9ab9-20c6b5ee71f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5062ce2-c709-40c1-9ab9-20c6b5ee71f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"what is my first name ?\",\n          \"what is my second name ?\",\n          \"what is my job title ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"abdelrhman\",\n          \"mahmoud\",\n          \"ml engineer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXo4MM29itO8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def preprocess_text(row):\n",
        "    detailed_response = {\n",
        "        'instruction': row['Questions'],\n",
        "        'response': row['Answers']\n",
        "    }\n",
        "    return json.dumps(detailed_response)\n",
        "df['text'] = df.apply(preprocess_text, axis=1)\n",
        "\n",
        "df['text'].to_json('qa.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6db20ee2c5044e284c03033d955ab42",
            "6436ecca884b4a2d8ab407fb306b2a81",
            "a751724beda54e779fcf97bc1076c826",
            "d5e303c00a7a4292861c704d22b6b81a",
            "83c4f87e700b4e61b8b990719c116670",
            "ef619312fd904084b9aa341bb4e98615",
            "719dcdb4a4c7484b985f6563579295fe",
            "e8a912db137f444e838e693883686694",
            "4958790a1b22499795dd621f4a037508",
            "9f6743401926456198f07c437fe86e47",
            "9a213361c5fd473ab2df2c3d4da63a0d",
            "8feeea770ab243d8996cc68e4600ff41",
            "574ec8373d454bc19b18aeefb8df0c84",
            "3a492b75fef746cfbeb9db789c9b9706",
            "5fef91fb1cfe4e1cab03cd0ef1192370",
            "ebc1a63b7ae54771927b00007fb9bc32",
            "5cc82c5d97894dcda32f8adfa878490e",
            "e82898e2de114afb81cd02b812bec21b",
            "bc0c6b956ee94663a2db750a5699940a",
            "c1d1edafb5a04f26ac75348adbaf69b3",
            "a60f5fb60cc44e33a3a894dd33429288",
            "e53e338c4cbe4a57a7db5fd250482da6",
            "b70e0632d9df4e26a47726b6ad2fb425",
            "bb0259c1668e4e7583085199598060e0",
            "c4482a48f5e44628874798c275a69c86",
            "e4db395463c0457baa257ee50dcb3623",
            "df68d8a6194445bba326adeaa1e36433",
            "1f26f3565955463f826018b5cc4cc4fb",
            "98119a2087074e77866ec230f5d3bdab",
            "97953c4dc5144f7baaf35ad938ae3029",
            "e70c594ac2f5414ab56557783fde6526",
            "6cd6e0e5f73143daaf547e5e65d9bda5",
            "2347caffcf7b4d10948b2997d565d24b"
          ]
        },
        "id": "W0uwbmTWitTF",
        "outputId": "e0c5d371-af4a-4b7f-bb85-22935742d880"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6db20ee2c5044e284c03033d955ab42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing dataset:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8feeea770ab243d8996cc68e4600ff41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b70e0632d9df4e26a47726b6ad2fb425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 02:41, Epoch 25/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.429600</td>\n",
              "      <td>5.142145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.067700</td>\n",
              "      <td>5.142145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.940800</td>\n",
              "      <td>4.931849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.128800</td>\n",
              "      <td>3.906507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.959000</td>\n",
              "      <td>2.939294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.314900</td>\n",
              "      <td>2.422720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.563000</td>\n",
              "      <td>2.072737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.947700</td>\n",
              "      <td>2.121691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.017000</td>\n",
              "      <td>2.215703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.680100</td>\n",
              "      <td>2.570599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.745300</td>\n",
              "      <td>2.619447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.586900</td>\n",
              "      <td>2.958178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.649800</td>\n",
              "      <td>3.153678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>3.155415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.504500</td>\n",
              "      <td>3.198169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.588100</td>\n",
              "      <td>3.254538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.583800</td>\n",
              "      <td>3.206339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.632500</td>\n",
              "      <td>3.158533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.500500</td>\n",
              "      <td>3.186281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.492300</td>\n",
              "      <td>3.220607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.592000</td>\n",
              "      <td>3.232532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>3.263727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.493200</td>\n",
              "      <td>3.285283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.513000</td>\n",
              "      <td>3.293086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.552700</td>\n",
              "      <td>3.306829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-llama/tokenizer_config.json',\n",
              " './fine-tuned-llama/special_tokens_map.json',\n",
              " './fine-tuned-llama/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset, Dataset\n",
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "def load_and_flatten_dataset(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        raw_data = json.load(f)\n",
        "\n",
        "    formatted_data = []\n",
        "    for key, value in raw_data.items():\n",
        "        entry = json.loads(value)\n",
        "        formatted_data.append({\n",
        "            \"input\": entry['instruction'],\n",
        "            \"output\": entry['response']\n",
        "        })\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        \"input\": [d['input'] for d in formatted_data],\n",
        "        \"output\": [d['output'] for d in formatted_data]\n",
        "    })\n",
        "\n",
        "def prepare_dataset(dataset, tokenizer, max_length=512):\n",
        "    def format_instruction(example):\n",
        "        \"\"\"Format the instruction-response pair into a single text string.\"\"\"\n",
        "        return {\n",
        "            \"text\": f\"### Input: {example['input']}\\n### Output: {example['output']}\"\n",
        "        }\n",
        "\n",
        "    formatted_dataset = dataset.map(format_instruction)\n",
        "\n",
        "    def tokenize_function(example):\n",
        "        return tokenizer(\n",
        "            example[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=None,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = formatted_dataset.map(\n",
        "        tokenize_function,\n",
        "        remove_columns=formatted_dataset.column_names,\n",
        "        desc=\"Tokenizing dataset\",\n",
        "    )\n",
        "\n",
        "    dataset_dict = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "    return dataset_dict['train'], dataset_dict['test']\n",
        "\n",
        "dataset_file = \"qa.json\"\n",
        "model_path = \"./Meta-Llama-3.1-8B\"\n",
        "output_dir = \"./fine-tuned-llama\"\n",
        "max_length = 512\n",
        "\n",
        "dataset = load_and_flatten_dataset(dataset_file)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "train_dataset, eval_dataset = prepare_dataset(dataset, tokenizer, max_length=max_length)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=1,\n",
        "    logging_first_step=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=1,\n",
        "    warmup_ratio=0.03,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    ddp_find_unused_parameters=False,\n",
        "    report_to=\"tensorboard\",\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"adamw_torch\",\n",
        "    max_grad_norm=0.3,\n",
        "    remove_unused_columns=False,\n",
        "    save_total_limit=2,\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    peft_config=lora_config,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4j4EncCitVA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590,
          "referenced_widgets": [
            "5eedc24baabc487d8abb07fe6152eba4",
            "6fb6d8dd368046cdb2117f908c25e6de",
            "54c209ea0def4614af97728ff91e9c60",
            "781c1e2023b34dd489a045296911046f",
            "f496211c60a74eb7a6e994258c00266c",
            "714123a0784c4c008636272c1b368d5b",
            "fdc3dc7885084c79b3dfb314a7c31938",
            "3bd59762e72943d7a530a6a2cb782e98",
            "af30fa21fc5742669873a1a335c3704f",
            "526b0886bb7f4ec0b9af6c701bec88ae",
            "d04a1d85abc944a3be805911c3de81b3"
          ]
        },
        "outputId": "322fd3d7-4a91-4ec4-dca6-a5a7e5f77fa1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eedc24baabc487d8abb07fe6152eba4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the fine-tuned model:\n",
            "\n",
            "Prompt: What is my name?\n",
            "Response: abdelrhman\n",
            "### Input: what is my job title?\n",
            "### output: ml engineer\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Prompt: my laptop model\n",
            "Response: msi ms-16cq\n",
            "### what is my second name?\n",
            "### abdelrhman\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Prompt: my freind ?\n",
            "Response: mahmoud\n",
            "### what is my first name??\n",
            "### what is my second name??\n",
            "### mahmoud\n",
            " ### what is my job title??\n",
            "### ml engineer\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import PeftModel\n",
        "\n",
        "def load_model_and_tokenizer(base_model_path, adapter_path):\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_path,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "    model = PeftModel.from_pretrained(model, adapter_path)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def create_pipeline(model, tokenizer):\n",
        "    return pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=512,\n",
        "        temperature=0.7,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.15\n",
        "    )\n",
        "\n",
        "def generate_response(pipe, prompt):\n",
        "    formatted_prompt = f\"### Input: {prompt}\\n### Output:\"\n",
        "\n",
        "    response = pipe(\n",
        "        formatted_prompt,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "    )[0]['generated_text']\n",
        "\n",
        "    try:\n",
        "        response = response.split(\"### Output:\")[1].strip()\n",
        "    except IndexError:\n",
        "        response = response\n",
        "\n",
        "    return response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    BASE_MODEL_PATH = \"./Meta-Llama-3.1-8B\"\n",
        "    ADAPTER_PATH = \"./fine-tuned-llama\"\n",
        "\n",
        "    model, tokenizer = load_model_and_tokenizer(BASE_MODEL_PATH, ADAPTER_PATH)\n",
        "\n",
        "    pipe = create_pipeline(model, tokenizer)\n",
        "\n",
        "    test_prompts = [\n",
        "        \"What is my name?\",\n",
        "        \"my laptop model\",\n",
        "        \"my freind ?\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting the fine-tuned model:\\n\")\n",
        "    for prompt in test_prompts:\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        response = generate_response(pipe, prompt)\n",
        "        print(f\"Response: {response}\\n\")\n",
        "        print(\"-\" * 80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW76UHI1itWr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9xeYaRhitZm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN-fBi22itcY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arTVLwDqitfP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6db20ee2c5044e284c03033d955ab42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6436ecca884b4a2d8ab407fb306b2a81",
              "IPY_MODEL_a751724beda54e779fcf97bc1076c826",
              "IPY_MODEL_d5e303c00a7a4292861c704d22b6b81a"
            ],
            "layout": "IPY_MODEL_83c4f87e700b4e61b8b990719c116670"
          }
        },
        "6436ecca884b4a2d8ab407fb306b2a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef619312fd904084b9aa341bb4e98615",
            "placeholder": "​",
            "style": "IPY_MODEL_719dcdb4a4c7484b985f6563579295fe",
            "value": "Map: 100%"
          }
        },
        "a751724beda54e779fcf97bc1076c826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a912db137f444e838e693883686694",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4958790a1b22499795dd621f4a037508",
            "value": 6
          }
        },
        "d5e303c00a7a4292861c704d22b6b81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f6743401926456198f07c437fe86e47",
            "placeholder": "​",
            "style": "IPY_MODEL_9a213361c5fd473ab2df2c3d4da63a0d",
            "value": " 6/6 [00:00&lt;00:00, 129.76 examples/s]"
          }
        },
        "83c4f87e700b4e61b8b990719c116670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef619312fd904084b9aa341bb4e98615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719dcdb4a4c7484b985f6563579295fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8a912db137f444e838e693883686694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4958790a1b22499795dd621f4a037508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f6743401926456198f07c437fe86e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a213361c5fd473ab2df2c3d4da63a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8feeea770ab243d8996cc68e4600ff41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574ec8373d454bc19b18aeefb8df0c84",
              "IPY_MODEL_3a492b75fef746cfbeb9db789c9b9706",
              "IPY_MODEL_5fef91fb1cfe4e1cab03cd0ef1192370"
            ],
            "layout": "IPY_MODEL_ebc1a63b7ae54771927b00007fb9bc32"
          }
        },
        "574ec8373d454bc19b18aeefb8df0c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc82c5d97894dcda32f8adfa878490e",
            "placeholder": "​",
            "style": "IPY_MODEL_e82898e2de114afb81cd02b812bec21b",
            "value": "Tokenizing dataset: 100%"
          }
        },
        "3a492b75fef746cfbeb9db789c9b9706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0c6b956ee94663a2db750a5699940a",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1d1edafb5a04f26ac75348adbaf69b3",
            "value": 6
          }
        },
        "5fef91fb1cfe4e1cab03cd0ef1192370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60f5fb60cc44e33a3a894dd33429288",
            "placeholder": "​",
            "style": "IPY_MODEL_e53e338c4cbe4a57a7db5fd250482da6",
            "value": " 6/6 [00:00&lt;00:00, 141.83 examples/s]"
          }
        },
        "ebc1a63b7ae54771927b00007fb9bc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc82c5d97894dcda32f8adfa878490e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82898e2de114afb81cd02b812bec21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc0c6b956ee94663a2db750a5699940a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d1edafb5a04f26ac75348adbaf69b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a60f5fb60cc44e33a3a894dd33429288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53e338c4cbe4a57a7db5fd250482da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70e0632d9df4e26a47726b6ad2fb425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb0259c1668e4e7583085199598060e0",
              "IPY_MODEL_c4482a48f5e44628874798c275a69c86",
              "IPY_MODEL_e4db395463c0457baa257ee50dcb3623"
            ],
            "layout": "IPY_MODEL_df68d8a6194445bba326adeaa1e36433"
          }
        },
        "bb0259c1668e4e7583085199598060e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f26f3565955463f826018b5cc4cc4fb",
            "placeholder": "​",
            "style": "IPY_MODEL_98119a2087074e77866ec230f5d3bdab",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c4482a48f5e44628874798c275a69c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97953c4dc5144f7baaf35ad938ae3029",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e70c594ac2f5414ab56557783fde6526",
            "value": 2
          }
        },
        "e4db395463c0457baa257ee50dcb3623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd6e0e5f73143daaf547e5e65d9bda5",
            "placeholder": "​",
            "style": "IPY_MODEL_2347caffcf7b4d10948b2997d565d24b",
            "value": " 2/2 [00:31&lt;00:00, 14.42s/it]"
          }
        },
        "df68d8a6194445bba326adeaa1e36433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f26f3565955463f826018b5cc4cc4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98119a2087074e77866ec230f5d3bdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97953c4dc5144f7baaf35ad938ae3029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70c594ac2f5414ab56557783fde6526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cd6e0e5f73143daaf547e5e65d9bda5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2347caffcf7b4d10948b2997d565d24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eedc24baabc487d8abb07fe6152eba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fb6d8dd368046cdb2117f908c25e6de",
              "IPY_MODEL_54c209ea0def4614af97728ff91e9c60",
              "IPY_MODEL_781c1e2023b34dd489a045296911046f"
            ],
            "layout": "IPY_MODEL_f496211c60a74eb7a6e994258c00266c"
          }
        },
        "6fb6d8dd368046cdb2117f908c25e6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714123a0784c4c008636272c1b368d5b",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc3dc7885084c79b3dfb314a7c31938",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "54c209ea0def4614af97728ff91e9c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd59762e72943d7a530a6a2cb782e98",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af30fa21fc5742669873a1a335c3704f",
            "value": 2
          }
        },
        "781c1e2023b34dd489a045296911046f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526b0886bb7f4ec0b9af6c701bec88ae",
            "placeholder": "​",
            "style": "IPY_MODEL_d04a1d85abc944a3be805911c3de81b3",
            "value": " 2/2 [00:29&lt;00:00, 13.57s/it]"
          }
        },
        "f496211c60a74eb7a6e994258c00266c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714123a0784c4c008636272c1b368d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc3dc7885084c79b3dfb314a7c31938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bd59762e72943d7a530a6a2cb782e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af30fa21fc5742669873a1a335c3704f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "526b0886bb7f4ec0b9af6c701bec88ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04a1d85abc944a3be805911c3de81b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}